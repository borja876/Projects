{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this dataset of airline arrival information to predict how late flights will be. A flight only counts as late if it is more than 30 minutes late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA as sklearn_pca\n",
    "from locale import atof\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and import data\n",
    "airlines = pd.read_csv('Airlines 2008.csv')\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the ArrDelay variable into a categorical variable\n",
    "airlines.loc[airlines['ArrDelay'] <= 30, 'ArrDelay'] = 0\n",
    "airlines.loc[airlines['ArrDelay'] > 30, 'ArrDelay'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check length of the dataset\n",
    "len(airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type of info per column of the dataset\n",
    "airlines.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average number of delayed flights per month\n",
    "grouped = airlines[['ArrDelay', 'DayofMonth']].groupby('DayofMonth').mean()\n",
    "\n",
    "# plot average delays by month\n",
    "grouped.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average number of delayed flights per month\n",
    "grouped = airlines[['ArrDelay', 'DayOfWeek']].groupby('DayOfWeek').mean()\n",
    "\n",
    "# plot average delays by month\n",
    "grouped.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average number of delayed flights per month\n",
    "airlines['hour'] = airlines['CRSArrTime'].map(lambda x: int(str(int(x)).zfill(4)[:2]))\n",
    "grouped = airlines[['ArrDelay', 'hour' ]].groupby('hour').mean()\n",
    "\n",
    "# plot average delays by month\n",
    "grouped.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average number of delayed flights per month\n",
    "grouped = airlines[['ArrDelay', 'Month']].groupby('Month').mean()\n",
    "\n",
    "# plot average delays by month\n",
    "grouped.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average number of delayed flights per month\n",
    "grouped = airlines[['ArrDelay', 'Month']].groupby('Month').mean()\n",
    "\n",
    "# plot average delays by month\n",
    "grouped.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of Nan in the Dataframe\n",
    "airlines.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop columns that are not going to be used\n",
    "airlines1 = airlines.drop(airlines[['Year','Month','UniqueCarrier','FlightNum',\n",
    "                                    'TailNum','Origin','Dest',\n",
    "                                    'CancellationCode',\n",
    "                                   'CarrierDelay',\n",
    "                                   'WeatherDelay',\n",
    "                                   'NASDelay',\n",
    "                                   'SecurityDelay',\n",
    "                                   'LateAircraftDelay']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean columns that have NAn\n",
    "airlines2=airlines1.drop(airlines1[['DepTime','ActualElapsedTime',\n",
    "                                    'CRSElapsedTime','AirTime',\n",
    "                                    'DepDelay','TaxiIn','TaxiOut','AirTime','Cancelled','Diverted'\n",
    "                                    ]],axis=1)\n",
    "\n",
    "airlines2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the values that still have NAN\n",
    "airlines2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all columns with NAN\n",
    "airlines3 = airlines2.dropna(how='any') \n",
    "airlines3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the new dataset\n",
    "airlines3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of datapoints for ArrDelay\n",
    "airlines3['ArrDelay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample majority class\n",
    "\n",
    "# Separate majority and minority classes\n",
    "airlines_majority = airlines3[airlines3.ArrDelay==0]\n",
    "airlines_minority = airlines3[airlines3.ArrDelay==1]\n",
    " \n",
    "# Downsample mairlinesass\n",
    "airlines_majority_downsampled = resample(airlines_majority, replace=False, n_samples=901398, random_state=123) \n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "airlines_downsampled = pd.concat([airlines_majority_downsampled, airlines_minority])\n",
    " \n",
    "# Display new class counts\n",
    "airlines_downsampled.ArrDelay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Outcome & Predictors\n",
    "\n",
    "y = airlines_downsampled['ArrDelay']\n",
    "X = airlines_downsampled.drop('ArrDelay',axis=1)\n",
    "\n",
    "#Scale the data\n",
    "names = X.columns\n",
    "X = pd.DataFrame(preprocessing.scale(X), columns = names)\n",
    "\n",
    "#Split into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#KFOld\n",
    "kf = KFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PReprocess and scale data\n",
    "names = X.columns\n",
    "X_scaled = pd.DataFrame(preprocessing.scale(X), columns = names)\n",
    "summary = X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Analysis\n",
    "\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform\n",
    "X_std = sc.fit_transform(X_scaled)\n",
    "\n",
    "# Create a PCA object with the 30 components as a parameter\n",
    "pca = decomposition.PCA(n_components=7)\n",
    "\n",
    "# Fit the PCA and transform the data\n",
    "X_std_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# View the new feature data's shape\n",
    "X_std_pca.shape\n",
    "\n",
    "# Create a new dataframe with the new features\n",
    "\n",
    "X1 = pd.DataFrame(X_std_pca)\n",
    "X1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize and fit the model.\n",
    "lr = LogisticRegression()\n",
    "fittrain = lr.fit(X_train,y_train)\n",
    "fittest = lr.fit(X_test,y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtrain_y = lr.predict(X_train)\n",
    "predtest_y = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Training Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_train, predtrain_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_train, predtrain_y)\n",
    "print(cnf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predtrain_y, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(train_tI_errors, train_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtest_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtest_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtest_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(test_tI_errors, test_tII_errors))\n",
    "print(cross_val_score(lr,X,y,cv=kf))\n",
    "print(cross_val_score(lr,X,y,cv=kf).mean())\n",
    "print('Cross validation PCA:', cross_val_score(lr,X1,y,cv=kf).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.fit(X_test, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtrainrf_y = rf.predict(X_train)\n",
    "predtestrf_y = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_train, predtrainrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_train, predtrainrf_y)\n",
    "print(cnf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predtrainrf_y, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(train_tI_errors, train_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Scores\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, predtestrf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestrf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestrf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(test_tI_errors, test_tII_errors))\n",
    "print(cross_val_score(rf,X,y,cv=kf))\n",
    "print(cross_val_score(rf,X,y,cv=kf).mean())\n",
    "print('Cross validation PCA:', cross_val_score(lr,X1,y,cv=kf).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVC***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and fit the model\n",
    "clf1 = SVC(kernel='linear', \n",
    "            class_weight='balanced',\n",
    "            probability=True)\n",
    " \n",
    "clf1.fit(X_train, y_train)\n",
    "clf1.fit(X_test,y_test)\n",
    " \n",
    "# Predict on training set\n",
    "predtrainclf_y = clf1.predict(X_train)\n",
    "predtestclf_y = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_train, predtrainclf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_train, predtrainclf_y)\n",
    "print(cnf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predtrainclf_y, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(train_tI_errors, train_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtestclf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestclf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestclf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(test_tI_errors, test_tII_errors))\n",
    "print(cross_val_score(clf1,X,y,cv=kf))\n",
    "print(cross_val_score(clf1,X,y,cv=kf).mean())\n",
    "print('Cross validation PCA:', cross_val_score(lr,X1,y,cv=kf).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosting Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.fit(X_test, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtrainclf_y = clf.predict(X_train)\n",
    "predtestclf_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_train, predtrainclf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_train, predtrainclf_y)\n",
    "print(cnf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predtrainclf_y, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    ").format(train_tI_errors, train_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "print(classification_report(y_test, predtestclf_y, target_names=target_names))\n",
    "cnf = confusion_matrix(y_test, predtestclf_y)\n",
    "print(cnf)\n",
    "\n",
    "table_test = pd.crosstab(y_test, predtestclf_y, margins=True)\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(test_tI_errors, test_tII_errors))\n",
    "print(cross_val_score(clf,X,y,cv=kf))\n",
    "print(cross_val_score(clf,X,y,cv=kf).mean())\n",
    "print('Cross validation PCA:', cross_val_score(lr,X1,y,cv=kf).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information we have about arilines and the delay they have experienced, we transform the delay from minutes into a categorical variable: 0 if th delay on arrival is less than 30 min and 1 if it is euqal or more.\n",
    "When cleaning the dataset, all the missing datapoints have been taken out (more than 9m entries in total) without significantly impacting the dataset.\n",
    "The dataset has been downsampled to the delays so that both classes are balanced when training different models. It has been downsampled considering the delays to reduce the computational power required.\n",
    "In the first pass, all remaining features have been applied after testing through PCA the max accuracy that the model can achieve.\n",
    "From all the models that have been tried, the one that best fits the data is the Gradient Boosting Classifier followed by the Random Forest one. Although both require a igh computational power, Random Forest require less.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
