{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences   Author\n",
       "0  Alice was beginning to get very tired of sitti...  Carroll\n",
       "1  So she was considering in her own mind (as wel...  Carroll\n",
       "2  There was nothing so VERY remarkable in that; ...  Carroll\n",
       "3                                           Oh dear!  Carroll\n",
       "4                                  I shall be late!'  Carroll"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize texts into sentences \n",
    "sent_tokenize_alice = sent_tokenize(alice)\n",
    "sent_tokenize_persuasion = sent_tokenize(persuasion)\n",
    "\n",
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in sent_tokenize_alice]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in sent_tokenize_persuasion]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "names = ['Sentences','Author']\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = names)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Challenge 0***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try support vector classifier with the current features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 90% has been achieved so we are 7% from our goal. Build new features based on Grammar, phrases and POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add column with 0 = Carroll and 1  = Austen\n",
    "sentences.loc[sentences['Author'] == 'Carroll', 'Target'] = 0\n",
    "sentences.loc[sentences['Author'] == 'Austen', 'Target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the predictors and the predicted variable\n",
    "X = sentences['Sentences']\n",
    "y = sentences['Target']\n",
    "\n",
    "#Split the data set into train and test 70/30\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size=0.33, random_state=135)\n",
    "\n",
    "#KFold for cross validation analysis\n",
    "kf = KFold(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#et up the vectorizer\n",
    "vectorize = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (1,4),\n",
    "                                              stop_words = 'english',\n",
    "                                              lowercase=True,\n",
    "                                              max_df=0.3,\n",
    "                            min_df=5,\n",
    "                            max_features=20000\n",
    "                       ).fit(X_train)\n",
    "\n",
    "        \n",
    "#analyzer = 'word',\n",
    " #                       stop_words = 'english',\n",
    "  #                      ngram_range = (1,3),\n",
    "   #                     max_df = 0.5,\n",
    "    #                    norm = 'l2',\n",
    "     #                   min_df = 5,\n",
    "      #                  use_idf = True,\n",
    "       #                 sublinear_tf  = True\n",
    "                        \n",
    "#Vectorize the train and test datasets\n",
    "X_train_vectorized = vectorize.transform(X_train)\n",
    "X_test_vectorized = vectorize.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borjaregueral/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.91323, std: 0.00594, params: {'C': 20, 'gamma': 0.001},\n",
       "  mean: 0.96269, std: 0.00118, params: {'C': 20, 'gamma': 0.01},\n",
       "  mean: 0.96213, std: 0.00243, params: {'C': 20, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 20, 'gamma': 1},\n",
       "  mean: 0.91549, std: 0.00586, params: {'C': 21, 'gamma': 0.001},\n",
       "  mean: 0.96213, std: 0.00078, params: {'C': 21, 'gamma': 0.01},\n",
       "  mean: 0.96213, std: 0.00243, params: {'C': 21, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 21, 'gamma': 1},\n",
       "  mean: 0.91775, std: 0.00657, params: {'C': 22, 'gamma': 0.001},\n",
       "  mean: 0.96241, std: 0.00104, params: {'C': 22, 'gamma': 0.01},\n",
       "  mean: 0.96269, std: 0.00183, params: {'C': 22, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 22, 'gamma': 1},\n",
       "  mean: 0.91917, std: 0.00717, params: {'C': 23, 'gamma': 0.001},\n",
       "  mean: 0.96184, std: 0.00118, params: {'C': 23, 'gamma': 0.01},\n",
       "  mean: 0.96241, std: 0.00211, params: {'C': 23, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 23, 'gamma': 1},\n",
       "  mean: 0.92114, std: 0.00795, params: {'C': 24, 'gamma': 0.001},\n",
       "  mean: 0.96213, std: 0.00078, params: {'C': 24, 'gamma': 0.01},\n",
       "  mean: 0.96269, std: 0.00277, params: {'C': 24, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 24, 'gamma': 1},\n",
       "  mean: 0.92228, std: 0.00799, params: {'C': 25, 'gamma': 0.001},\n",
       "  mean: 0.96297, std: 0.00078, params: {'C': 25, 'gamma': 0.01},\n",
       "  mean: 0.96269, std: 0.00277, params: {'C': 25, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 25, 'gamma': 1},\n",
       "  mean: 0.92425, std: 0.00724, params: {'C': 26, 'gamma': 0.001},\n",
       "  mean: 0.96382, std: 0.00105, params: {'C': 26, 'gamma': 0.01},\n",
       "  mean: 0.96213, std: 0.00212, params: {'C': 26, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 26, 'gamma': 1},\n",
       "  mean: 0.92736, std: 0.00626, params: {'C': 27, 'gamma': 0.001},\n",
       "  mean: 0.96439, std: 0.00119, params: {'C': 27, 'gamma': 0.01},\n",
       "  mean: 0.96213, std: 0.00212, params: {'C': 27, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 27, 'gamma': 1},\n",
       "  mean: 0.92793, std: 0.00658, params: {'C': 28, 'gamma': 0.001},\n",
       "  mean: 0.96467, std: 0.00106, params: {'C': 28, 'gamma': 0.01},\n",
       "  mean: 0.96213, std: 0.00212, params: {'C': 28, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 28, 'gamma': 1},\n",
       "  mean: 0.92878, std: 0.00632, params: {'C': 29, 'gamma': 0.001},\n",
       "  mean: 0.96495, std: 0.00079, params: {'C': 29, 'gamma': 0.01},\n",
       "  mean: 0.96156, std: 0.00174, params: {'C': 29, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 29, 'gamma': 1},\n",
       "  mean: 0.92934, std: 0.00708, params: {'C': 30, 'gamma': 0.001},\n",
       "  mean: 0.96495, std: 0.00144, params: {'C': 30, 'gamma': 0.01},\n",
       "  mean: 0.96184, std: 0.00208, params: {'C': 30, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 30, 'gamma': 1},\n",
       "  mean: 0.93104, std: 0.00663, params: {'C': 31, 'gamma': 0.001},\n",
       "  mean: 0.96382, std: 0.00242, params: {'C': 31, 'gamma': 0.01},\n",
       "  mean: 0.96156, std: 0.00174, params: {'C': 31, 'gamma': 0.1},\n",
       "  mean: 0.96213, std: 0.00105, params: {'C': 31, 'gamma': 1}],\n",
       " {'C': 29, 'gamma': 0.01},\n",
       " 0.96495210438799528)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the model\n",
    "svc = SVC(class_weight = 'balanced')\n",
    "\n",
    "#Create range of values to fit parameters\n",
    "Cs = np.arange(20,32)\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "    \n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "\n",
    "#Fit parameters\n",
    "svc1 = GridSearchCV(svc, param_grid=param_grid,n_jobs=-1,iid=False, cv=kf)\n",
    "\n",
    "#Fit the tunned model\n",
    "svc1.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Print the hyperparameters set\n",
    "svc1.grid_scores_, svc1.best_params_, svc1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit tunned model on Test set\n",
    "svc1.fit(X_test_vectorized, y_test)\n",
    "\n",
    "# Predict on training set\n",
    "predtest_y = svc1.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.96      0.96       521\n",
      "        1.0       0.98      0.99      0.98      1223\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1744\n",
      "\n",
      "[[ 498   23]\n",
      " [  16 1207]]\n",
      "SVC accuracy:0.9392227722869878\n",
      "Type I error:0.013188073394495414\n",
      "Type II error:0.009174311926605505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test Scores\n",
    "target_names = ['0.0', '1.0']\n",
    "\n",
    "#Build confusion matrix\n",
    "cnf = confusion_matrix(y_test, predtest_y)\n",
    "\n",
    "#Calcualte type I and type II errors\n",
    "table_test = pd.crosstab(y_test, predtest_y, margins=True)\n",
    "tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "\n",
    "#Print accruacy results\n",
    "print(classification_report(y_test, predtest_y, target_names=target_names))\n",
    "print(cnf)\n",
    "print((\n",
    "    'SVC accuracy:{}\\n'\n",
    "    'Type I error:{}\\n'\n",
    "    'Type II error:{}\\n'\n",
    ").format(cross_val_score(svc1,X_test_vectorized,y_test,cv=kf).mean(), tI_errors, tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model considering tfidf\n",
    "text_clf = Pipeline([\n",
    "                      ('tfidf', TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)),\n",
    "                     ('clf', svc1)\n",
    "])\n",
    "\n",
    "#Fit the model on the train dataset\n",
    "text_clf = text_clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461104112079145"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the classifier on the test data set\n",
    "text_clf.fit(X_test_vectorized,y_test)\n",
    "\n",
    "#Calculate accuracy with cross validation\n",
    "cross_val_score(text_clf,X_test_vectorized,y_test,cv=kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
