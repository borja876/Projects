{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "import logging\n",
    "import sys\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from time import time\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold, cross_val_predict, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline\n",
    "get_ipython().magic('pylab inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this challenge is to classify authors using different novels that they have written. In this case  supervised techniques have been used and compared to see which one is giving better results using tfidf and bag of words in all of them. Regarding the corpus, then authors have been chosen randomly from Gutenberg Project and 7 novels from those authors. Although initially ten novesl were picked, due to computing restrictions only seven have been left for the classification purposes. The authors that have been picked are:\n",
    "\n",
    "1. Jane Austen\n",
    "2. Chesterton\n",
    "3. Conan Doyle\n",
    "4. Charles Dickens\n",
    "5. Elliot\n",
    "\n",
    "In this notebook we will see the following steps:\n",
    "\n",
    "1. Retreive and store the data creating the dataset\n",
    "2. Cleanse and parse and tokenize texts\n",
    "3. Generate features and select the most appropiate for the models\n",
    "4. Supervised models\n",
    "5. Increase the performance of one of the models by 5 percentage points\n",
    "\n",
    "To run the supervised parts of this challenge a new virtual machine has been set up to improve the computational performance. After initial trials on the machine with increased RAM 12GB, the conditions of the challenge were too resource intensive reasing why a virtual machine 8 vCPUs, 30 GB memory was set using Google Compute Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retreive and store the data creating the dataset ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten novels from four different authors have been retreived form Gutenberg project and a list of all the book files is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of our book files.\n",
    "book_filenames_austen = sorted(glob.glob(\"/home/borjaregueral/challengesuper2/austen/*.txt\"))\n",
    "book_filenames_chesterton = sorted(glob.glob(\"/home/borjaregueral/challengesuper2/chesterton/*.txt\"))\n",
    "book_filenames_conandoyle = sorted(glob.glob(\"/home/borjaregueral/challengesuper2/conandoyle/*.txt\"))\n",
    "book_filenames_elliot = sorted(glob.glob(\"/home/borjaregueral/challengesuper2/elliot/*.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is added to the copus and stored as raw books so that they can be cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading '/home/borjaregueral/challengesuper2/austen/austen-emma.txt'...\n",
      "Corpus is now 795775 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/austen/austen-persuasion.txt'...\n",
      "Corpus is now 1262067 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/chesterton/chesterton-allthingsconsidered.txt'...\n",
      "Corpus is now 337425 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/chesterton/chesterton-ballad.txt'...\n",
      "Corpus is now 451666 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/chesterton/chesterton-brown.txt'...\n",
      "Corpus is now 858295 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/chesterton/chesterton-orthodoxy.txt'...\n",
      "Corpus is now 1218851 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/conandoyle/conandoyle-adventuressh.txt'...\n",
      "Corpus is now 594916 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/conandoyle/conandoyle-lostworld.txt'...\n",
      "Corpus is now 1046701 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/elliot/elliot-adambede.txt'...\n",
      "Corpus is now 468860 characters long\n",
      "\n",
      "Reading '/home/borjaregueral/challengesuper2/elliot/elliot-deronda.txt'...\n",
      "Corpus is now 2210160 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read and add the text of each book to corpus_raw.\n",
    "corpus_raw_austen = u\"\"\n",
    "for book_filename in book_filenames_austen:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw_austen += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw_austen)))\n",
    "    print()\n",
    "    \n",
    "#Read and add the text of each book to corpus_raw.\n",
    "corpus_raw_chesterton = u\"\"\n",
    "for book_filename in book_filenames_chesterton:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw_chesterton += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw_chesterton)))\n",
    "    print()\n",
    "#Read and add the text of each book to corpus_raw.\n",
    "corpus_raw_conandoyle = u\"\"\n",
    "for book_filename in book_filenames_conandoyle:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw_conandoyle += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw_conandoyle)))\n",
    "    print()\n",
    "\n",
    "#Read and add the text of each book to corpus_raw.\n",
    "corpus_raw_elliot = u\"\"\n",
    "for book_filename in book_filenames_elliot:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw_elliot += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw_elliot)))\n",
    "    print()\n",
    "\n",
    "doc_complete = [corpus_raw_austen, corpus_raw_chesterton, corpus_raw_conandoyle,\n",
    "                 corpus_raw_elliot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleanse and parse and tokenize text###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating the features, and to increase the explanatory power of them, text has been cleaned and parsed accordingly. The books have gone through an initial set of cleansing actions before been parsed using Spacy, to reduce the computing effort required by the latter and then have been cleaned again before the feature generation.\n",
    "\n",
    "The initial cleansing action has had three steps. The first step consisted on deleting all references to the Gutenberg Project from every book. This way, it has been avoided that words like “Gutenberg” and “Gutenberg Project” appear as features and distort the clustering of the authors.\n",
    "\n",
    "As described below, cleaning actions have gone from removing all references to chapters, digits double whitespaces and references to numbers like dates and ordinal numbers. This has been followed by removing punctuation and common stop words that will only add noise to the features that are generated afterwards.\n",
    "\n",
    "The remaining words, considered to have the most explanatory power regarding each of the titles from the authors, have been lemmatized and stemmed reducing up to 60% the computing resources needed. In the first case words from the same family are reduced to their lemmas and in the second case, additional prefixes and suffixes are removed. All cleaning operations have been carried out in a way that remaining sentences are stored in a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a set of stopwords in english from nltk\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# Create a set of punctuation marks to exclude them from the text\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "# Call the lemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "#Define a cleaning function that incorporates the different steps in the pipeline to clean the texts\n",
    "def clean(doc):\n",
    "    doc = re.sub(r'--',' ',doc)\n",
    "    doc = re.sub(\"[\\[].*?[\\]]\", \"\", doc)\n",
    "    doc = re.sub(r'Chapter \\d+', '', doc)\n",
    "    doc = re.sub(r'CHAPTER .*', '', doc)\n",
    "    doc = re.sub('[0-9]+', '', doc)\n",
    "    doc = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", doc)\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "#Create a list of lists with all the documents\n",
    "doc_clean = [clean(doc) for doc in doc_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels\n",
    "#load spacy for english language as all novels are in english\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#Parse novels one by one to maintain the author tagging\n",
    "austen_doc = nlp(doc_clean[0])\n",
    "chesterton_doc = nlp(doc_clean[1])\n",
    "conandoyle_doc = nlp(doc_clean[2])\n",
    "elliot_doc = nlp(doc_clean[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7690cc2dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7690cc26d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "austen_sents = [[str(sent), \"Austen\"] for sent in austen_doc.sents]\n",
    "chesterton_sents = [[str(sent), \"Chesterton\"] for sent in chesterton_doc.sents]\n",
    "conandoyle_sents = [[str(sent), \"Conandoyle\"] for sent in conandoyle_doc.sents]\n",
    "elliot_sents = [[str(sent), \"elliot\"] for sent in elliot_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "names = ['Sentences','Author']\n",
    "sent = pd.DataFrame(austen_sents + chesterton_sents + \n",
    "                    conandoyle_sents + \n",
    "                    elliot_sents, columns = names)\n",
    "\n",
    "\n",
    "#Plot the contribution of each author to the corpus (sentences)\n",
    "sent.Author.value_counts().plot(kind='bar', grid=False, figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aadd numerical column to tag the authors for supervised classification\n",
    "sent.loc[sent['Author'] == 'Austen', 'Target'] = 0\n",
    "sent.loc[sent['Author'] == 'Chesterton', 'Target'] = 1\n",
    "sent.loc[sent['Author'] == 'Conandoyle', 'Target'] = 2\n",
    "sent.loc[sent['Author'] == 'elliot', 'Target'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate features and select the most appropiate for the models ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Features using BoW***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texts have been vectorized using bag of words. In this case the algorithm counts the numnber of times a word appears in a certain text. During the creation of the bag of words space, ngrams up to 4 components have been considered and stop words in english to remove noise from the dataset. Due to the authors that have been chosen, this method will bias the models towards the authors that have longer texts being Elliot and Austen compared to Conan Doyle and Chesterton. The total number of features is 52k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10802, 52727)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform into Bag of Words\n",
    "vec = CountVectorizer(max_df = 0.75 , min_df = 2 , ngram_range = (1,4), stop_words = 'english')\n",
    "\n",
    "#Build the predictors and the predicted variable applying BoW.\n",
    "X = vec.fit_transform(sent['Sentences'])\n",
    "y = sent['Target']\n",
    "\n",
    "#Split the data set into train and test 70/30\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow  = train_test_split(X,y, test_size=0.30, random_state=1234)\n",
    "\n",
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Features using Tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using tfidf, the frequency of appearance is normalized and also considered the ones that appear in less than 75% of the documents. With this method, the value counts are smoothen considering additional features of the word such as the amount of information it adds to describe the novel. As in the case of the ba og words, ngamrs up to four have been considered, stop words removed and thesublinear_tf used. It Apply scales the word count obtained and smoothened by the frequency of appearence in the document and whithin a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform into Tf-idf considering the relative frequency\n",
    "vect = TfidfVectorizer(norm = 'l2', max_df = 0.75 , min_df = 2 , ngram_range = (1,4), stop_words = 'english',\n",
    "                       use_idf = True, sublinear_tf = True)\n",
    "\n",
    "#Build the predictors and the predicted variable applying BoW.\n",
    "X_tfidf = vect.fit_transform(sent['Sentences'])\n",
    "y_tfidf = sent['Target']\n",
    "\n",
    "#Split the data set into train and test 70/30\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf  = train_test_split(X_tfidf,y_tfidf, test_size=0.30, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five folds have been defined and will be used to tune and evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold for cross validation analysis\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Supervised models ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models have been run using the features obtained through bag of words and tfidf. In this case results are compared to see which one gives a better overall accuracy as it has been used as the score function. In all cases cross validation over five folds is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Bag of Words***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Logistic Regression Classifier is trained using the features obtained through tfidf. Additionally, using fridsearch the parameters are tunned. As length of texts and therefore the features per author are not balanced, the class weight is set up so that is consideres unbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters logistic regression BoW:\n",
      " {'C': 0.5, 'solver': 'newton-cg'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "log_reg_bow = LogisticRegression(class_weight='balanced', penalty = 'l2', multi_class= 'multinomial', max_iter = 1000)\n",
    "\n",
    "#Tune parameters: C parameter\n",
    "c_param = [ 0.1, 0.5, 1 ]\n",
    "\n",
    "#Tune the type of penalty used between l1 and l2\n",
    "\n",
    "solver_param = ['newton-cg', 'lbfgs']\n",
    "\n",
    "parameters = {'C': c_param, 'solver': solver_param}\n",
    "\n",
    "#Fit parameters\n",
    "log_reg_tuned_bow = GridSearchCV(log_reg_bow, param_grid=parameters, n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "log_reg_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters logistic regression BoW:\\n {}\\n').format(log_reg_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the parameters are tunned, the model is fit in the test dataset. As a measurement of the computing effort it requires 3.6 min to fit the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   35.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "log_reg_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = log_reg_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated on the test set. In this case the solver has been chosen between the different options that support multiclass classification. As it can be seen in the classification report the model presents overfitting being the precision and recall close to one in all classes expect for class five (Huxley) which is the one that reduces the overall accuracy of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.86      0.90      1091\n",
      "        1.0       0.91      0.88      0.89       509\n",
      "        2.0       0.94      0.87      0.90       684\n",
      "        3.0       0.90      0.96      0.93      2346\n",
      "\n",
      "avg / total       0.91      0.91      0.91      4630\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[ 943    9   14  125]\n",
      " [  12  449    3   45]\n",
      " [   8    8  594   74]\n",
      " [  52   30   20 2244]]\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   29.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression set accuracy BoW: 77.54 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}')\n",
    "       .format(classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print(('Confusion Matrix BoW: \\n\\n {}\\n'\n",
    ").format(confusion_bow))\n",
    "\n",
    "print(('Logistic Regression set accuracy BoW: {0:.2f} % \\n'\n",
    ").format(cross_val_score(log_reg_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model is computationally efficient as it fits the dataset with over 50k in less than  two minutes making it a string candidate to move intro production. The overall accuracy is nearly 77% which is roughly five percentage points more than in the challenge for this unit. The accuracy is higher than the one obainted by undsupervised methdos using clustering as is much more stable. In this case, the introduction of the test set, unseen by the model is not provoking unstable classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TF-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Logistic Regression Classifier is trained using the features obtained through tfidf. Additionally, using fridsearch the parameters are tunned. As length of texts and therefore the features per author are not balanced, the class weight is set up so that is consideres unbalanced classes. In this case the parameter of the model C is higher than the one used with the bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   49.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters logistic regression Tfidf: \n",
      "{'C': 1, 'solver': 'newton-cg'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "\n",
    "log_reg_tfidf = LogisticRegression(class_weight='balanced', penalty = 'l2', multi_class= 'multinomial', max_iter = 600)\n",
    "\n",
    "#Tune parameters\n",
    "#C parameter\n",
    "c_param = [ 0.1, 0.5, 1 ]\n",
    "\n",
    "#Tune the type of penalty used between l1 and l2\n",
    "\n",
    "solver_param = ['newton-cg','lbfgs']\n",
    "\n",
    "parameters = {'C': c_param, 'solver': solver_param}\n",
    "\n",
    "\n",
    "#Fit parameters\n",
    "log_reg_tuned_tfidf = GridSearchCV(log_reg_tfidf, param_grid=parameters, n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "log_reg_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters logistic regression Tfidf: \\n{}\\n'\n",
    "      ).format(log_reg_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the parameters are tunned, the model is fit in the test dataset. As a measurement of the computing effort it requires less than one min to fit the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   25.7s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "log_reg_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = log_reg_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated on the test set. In this case the solver has been chosen between the different options that support multiclass classification. As it can be seen in the classification report the model presents overfitting being the precision and recall close to one in all classes expect for class five (Huxley) which is the one that reduces the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tf-idf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.96      0.96      1091\n",
      "        1.0       0.92      0.98      0.94       509\n",
      "        2.0       0.96      0.95      0.96       684\n",
      "        3.0       0.98      0.96      0.97      2346\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4630\n",
      "\n",
      "Confusion Matrix Tf-idf: \n",
      "\n",
      " [[1052    6    6   27]\n",
      " [   6  497    0    6]\n",
      " [   8    6  652   18]\n",
      " [  35   34   22 2255]]\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression set accuracy Tf-idf: 80.43 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tf-idf: \\n {}')\n",
    "       .format(classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print(('Confusion Matrix Tf-idf: \\n\\n {}\\n'\n",
    ").format(confusion_tfidf))\n",
    "\n",
    "print(('Logistic Regression set accuracy Tf-idf: {0:.2f} % \\n'\n",
    ").format(cross_val_score(log_reg_tuned_tfidf, X_test_tfidf, y_test_tfidf,cv=kf).mean()*100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model is computationally efficient as it fits the dataset with over 80k in less than two minutes making it a string candidate to move intro production. The overall accuracy is nearly 80% which is roughly five percentage points more than in the challenge for this unit. The accuracy is higher than the one obainted by undsupervised methdos using clustering as is much more stable. In this case, the introduction of the test set, unseen by the model is not provoking unstable classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifiers ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bernoulli Classifier***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***Bag of Words ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bernoulli classifier has been tunned and trained in the feautures obtained through Tf-idf. In this case the simplicity of the model added to the good classification results make of this model a good candidate to move into production. The time required to train it is lower than the time required to train the logistic regression one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best paramenters logistic Naive-Bayes Bernoulli BoW: \n",
      "{'alpha': 0.0001}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "naive_bayes_bernoulli_bow = BernoulliNB()\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "alpha = [0.0001, 0.001, 0.01]\n",
    "parameters = {'alpha': alpha}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "naive_bayes_bernoulli_tuned_bow = GridSearchCV(naive_bayes_bernoulli_bow, n_jobs = -1, param_grid=parameters, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "naive_bayes_bernoulli_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters logistic Naive-Bayes Bernoulli BoW: \\n{}\\n').format(naive_bayes_bernoulli_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several runs, with different extremes in the values of the alpha parameter, the parameter chosen is always the one closer to zero. This means that the smoothing parameter is very low so the additive smoothing required is low. The model is fit within seconds which makes it a strong candidate (the best one from a computational and speed standpoint) to move intro production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "naive_bayes_bernoulli_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = naive_bayes_bernoulli_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated using cross validation and five folds. In this case as in the case of logistic regression the model presents overfitting as it can be seen from the classification report. Both precision and recall is one for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.88      0.93      1091\n",
      "        1.0       1.00      0.74      0.85       509\n",
      "        2.0       1.00      0.77      0.87       684\n",
      "        3.0       0.85      1.00      0.92      2346\n",
      "\n",
      "avg / total       0.92      0.91      0.91      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[ 958    0    0  133]\n",
      " [   6  376    0  127]\n",
      " [   5    0  527  152]\n",
      " [   0    0    0 2346]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Bernoulli Classifier set accuracy BoW: 81.75 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print(('Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print(('Bernoulli Classifier set accuracy BoW: {0:.2f} %\\n').format(cross_val_score(naive_bayes_bernoulli_tuned_bow,\n",
    "                                                                                X_test_bow,\n",
    "                                                                                y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model is slightly lower than the accuracy obtained with the logistic regression classifier. However, the time required to fit the model is at least one tenth of the time required for the logistic regression presenting both overfitting. Hence, if overall accuracy is what is tried to be improved, this is the best model with a very small loss of accuracy scoring 81.75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bernoulli classifier has been tunned and trained in the feautures obtained through Tf-idf. In this case the simplicity of the model added to the good classification results make of this model a good candidate to move into production. The time required to train it is lower than the time required to train the logistic regression one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best paramenters logistic Naive-Bayes Bernoulli Tfidf: \n",
      "{'alpha': 0.001}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "naive_bayes_bernoulli_tfidf = BernoulliNB()\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "alpha = [0.001, 0.01,0.1]\n",
    "parameters = {'alpha': alpha}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "naive_bayes_bernoulli_tuned_tfidf = GridSearchCV(naive_bayes_bernoulli_tfidf,\n",
    "                                                 n_jobs = -1,\n",
    "                                                 param_grid=parameters,\n",
    "                                                 cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "naive_bayes_bernoulli_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters logistic Naive-Bayes Bernoulli Tfidf: \\n{}\\n').format(naive_bayes_bernoulli_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several runs, with different extremes in the values of the alpha parameter, the parameter chosen is always the one closer to zero. This means that the smoothing parameter is very low so the additive smoothing required is low. The model is fit within seconds which makes it a strong candidate (the best one from a computational and speed standpoint) to move intro production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "naive_bayes_bernoulli_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = naive_bayes_bernoulli_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he model is evaluated using cross validation and five folds. In this case as in the case of logistic regression the model presents overfitting as it can be seen from the classification report. Both precision and recall is one for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.88      0.93      1091\n",
      "        1.0       1.00      0.72      0.83       509\n",
      "        2.0       1.00      0.75      0.86       684\n",
      "        3.0       0.84      1.00      0.91      2346\n",
      "\n",
      "avg / total       0.92      0.90      0.90      4630\n",
      "\n",
      "Confusion Matrix Tf-idf: \n",
      "\n",
      " [[ 957    0    0  134]\n",
      " [   6  364    0  139]\n",
      " [   6    0  515  163]\n",
      " [   0    0    0 2346]]\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Bernoulli Classifier Tf-Idf set accuracy Tf-idf: 81.58 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tfidf: \\n {}').format(classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print(('Confusion Matrix Tf-idf: \\n\\n {}\\n').format(confusion_tfidf))\n",
    "\n",
    "print(('Bernoulli Classifier Tf-Idf set accuracy Tf-idf: {0:.2f} % \\n').format(cross_val_score(naive_bayes_bernoulli_tuned_tfidf,\n",
    "                                                                                       X_test_tfidf,\n",
    "                                                                                       y_test_tfidf,\n",
    "                                                                                       cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model is slightly higher than the accuracy obtained with the logistic regression classifier (81.58%). However, the time required to fit the model is at least one tenth of the time required for the logistic regression presenting both overfitting. In this case is class seven (Shaw) the one that shows the lowest precision being the one that determines the lower value of the overall accuracy when compared to the Bernoulli model. Hence, if overall accuracy is what is tried to be improved, this is the best model with a very small loss of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Multinomial Classifier***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BoW***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multinomial classifier is trained on the features obtained using tfidf and evaluated on the holdout. In this case, as in the previous Navy Bayes classification used, alpha always gets the value cloaer to zero, therefore there is no additive smoothing used in this classifier. From a compuational effort standpoint, as in the previous case, this is the one that requires less time to fit making it a strong candidate to move into production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best paramenters Naive-Bayes Multinomial BoW:\n",
      " {'alpha': 0.5}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "naive_bayes_multinomial_bow = MultinomialNB()\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "alpha = [0.01,0.1,0.5]\n",
    "parameters = {'alpha': alpha}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "naive_bayes_multinomial_tuned_bow = GridSearchCV(naive_bayes_multinomial_bow,\n",
    "                                                 n_jobs = -1,\n",
    "                                                 param_grid=parameters,\n",
    "                                                 cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "naive_bayes_multinomial_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters Naive-Bayes Multinomial BoW:\\n {}\\n').format(\n",
    "naive_bayes_multinomial_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of alpha is in all trials the closest one to zero being the additive smoothing lose. In this case the time required for fitting is less than one minute. The model is then evaluated on the test set. For that, the first step is to fit the test hodout of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "naive_bayes_multinomial_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = naive_bayes_multinomial_tuned_bow.predict(X_test_bow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model presents overfitting and the accuracy is slightly higher than in the previous case 3% more. The confusion matrix presents a lower number of false positives and negatives for all categories, taking into account that the size of each of them is different results are consistent across all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.91      0.93      1091\n",
      "        1.0       0.97      0.85      0.90       509\n",
      "        2.0       0.99      0.82      0.90       684\n",
      "        3.0       0.90      0.99      0.94      2346\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[ 995    2    1   93]\n",
      " [  12  432    3   62]\n",
      " [  22   10  562   90]\n",
      " [  23    3    3 2317]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Multinomial Classifier set accuracy BoW: 84.13 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print((\n",
    "    'Multinomial Classifier set accuracy BoW: {0:.2f} %\\n'\n",
    ").format(cross_val_score(naive_bayes_multinomial_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time required to fit the model is lower than in any other case presenting a higher accuracy. In this case, the accuracy is close to 84.12% while the classification report shows values close to one, showing that there is overfitting. Hence, from the classifiers evaluated until now this is the one that presents better results, from an accuracy and a computational effort perspective. This is the best candidate to move into production for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multinomial classifier is trained on the features obtained using tfidf and evaluated on the holdout. In this case, as in the previous Navy Bayes classification used, alpha always gets the value cloaer to zero, therefore there is no additive smoothing used in this classifier. From a compuational effort standpoint, as in the previous case, this is the one that requires less time to fit making it a strong candidate to move into production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters Naive-Bayes Multinomial BoW:\n",
      " {'alpha': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "naive_bayes_multinomial_tfidf = MultinomialNB()\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "alpha = [0.01,0.1,0.5,1]\n",
    "parameters = {'alpha': alpha}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "naive_bayes_multinomial_tuned_tfidf = GridSearchCV(naive_bayes_multinomial_tfidf,\n",
    "                                                 n_jobs = -1,\n",
    "                                                 param_grid=parameters,\n",
    "                                                 cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "naive_bayes_multinomial_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters Naive-Bayes Multinomial BoW:\\n {}\\n').format(\n",
    "naive_bayes_multinomial_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he value of alpha is in all trials the closest one to zero being the additive smoothing lose. In this case the time required for fitting is less than one minute. The model is then evaluated on the test set. For that, the first step is to fit the test hodout of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "naive_bayes_multinomial_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = naive_bayes_multinomial_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model presents overfitting and the accuracy is slightly higher than in the previous case 3% more. The confusion matrix presents a lower number of false positives and negatives for all categories, taking into account that the size of each of them is different results are consistent across all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.96      0.96      1091\n",
      "        1.0       1.00      0.92      0.95       509\n",
      "        2.0       1.00      0.91      0.95       684\n",
      "        3.0       0.95      0.99      0.97      2346\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4630\n",
      "\n",
      "Confusion Matrix Tf-idf: \n",
      "\n",
      " [[1052    0    0   39]\n",
      " [   8  466    0   35]\n",
      " [  11    0  625   48]\n",
      " [  19    1    0 2326]]\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Multinomial Classifier set accuracy Tf-idf: 83.67 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report tfidf: \\n {}').format(classification_report(y_test_tfidf,\n",
    "                                                                          predtest_y_tfidf,\n",
    "                                                                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print(('Confusion Matrix Tf-idf: \\n\\n {}\\n').format(confusion_tfidf))\n",
    "\n",
    "print(('Multinomial Classifier set accuracy Tf-idf: {0:.2f} % \\n').format(cross_val_score(naive_bayes_multinomial_tuned_tfidf,\n",
    "                                                                                       X_test_tfidf,\n",
    "                                                                                       y_test_tfidf,\n",
    "                                                                                       cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time required to fit the model is lower than in any other case presenting a higher accuracy. In this case, the accuracy is close to 83.67% while the classification report shows values close to one, showing that there is overfitting. Hence, from the classifiers evaluated until now this is the one that presents better results, from an accuracy and a computational effort perspective. This is the best candidate to move into production for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bag of Words***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN classifier has been fit using bag of words. In this case during the gridsearch, five neighbors have been selected as the optimumm number of neighbors when using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best paramenters KNN BoW:\n",
      " {'n_neighbors': 5}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "KNN_bow = KNeighborsClassifier(weights = 'distance')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "neighbors = [3, 5, 7,9]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'n_neighbors': neighbors}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "KNN_tuned_bow = GridSearchCV(KNN_bow, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "KNN_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters KNN BoW:\\n {}\\n').format(\n",
    "KNN_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been tuned, it is fit in the test holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "KNN_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = KNN_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of the model is done using the classification report, confusion matrix and overall accuracy. In this case KNN works worse than other models as it does not have enough data. From the classification report it can be seen that the model is not overfitting having a high but not equal to one precision and recall. Author two is the one that is scoring the worst results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1091\n",
      "        1.0       0.98      0.98      0.98       509\n",
      "        2.0       0.99      0.96      0.98       684\n",
      "        3.0       0.99      0.99      0.99      2346\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[1081    1    0    9]\n",
      " [   6  498    0    5]\n",
      " [   7    2  656   19]\n",
      " [  12    6    4 2324]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "KNN accuracy BoW: 59.72 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print((\n",
    "    'KNN accuracy BoW: {0:.2f} %\\n'\n",
    ").format(cross_val_score(KNN_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is scoring really low from the accuracy that is normally achieved when using KNN. One of the reaons is the amount of data used to fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tf- idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit on the training set using the features obtained using tfidf. In this case the tuning of the model give lower parameters as the features have been already smoothened being the number of neighbors equal to three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best paramenters KNN Tfidf:\n",
      " {'n_neighbors': 3}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   16.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "KNN_tfidf = KNeighborsClassifier(weights = 'distance')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "neighbors = [3, 5, 7,9]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'n_neighbors': neighbors}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "KNN_tuned_tfidf = GridSearchCV(KNN_tfidf,\n",
    "                               param_grid=parameters,\n",
    "                               n_jobs = -1,\n",
    "                               cv=kf,\n",
    "                               verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "KNN_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters KNN Tfidf:\\n {}\\n').format(KNN_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the parameters are tuned the model is fit on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "KNN_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = KNN_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the accuracy obtained with tfidf is not very different from the accuracy obtained with the bag of words. Better results would be obtained if more data is used to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1091\n",
      "        1.0       0.98      0.98      0.98       509\n",
      "        2.0       0.99      0.96      0.98       684\n",
      "        3.0       0.99      0.99      0.99      2346\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4630\n",
      "\n",
      "\n",
      "Confusion Matrix Tfidf: \n",
      "\n",
      " [[1081    1    0    9]\n",
      " [   6  497    0    6]\n",
      " [   7    2  656   19]\n",
      " [  12    6    4 2324]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy Tfidf: 51.75 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tfidf: \\n {}\\n').format(\n",
    "    classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix Tfidf: \\n\\n {}\\n\\n').format(confusion_tfidf))\n",
    "\n",
    "print((\n",
    "    'KNN accuracy Tfidf: {0:.2f} %\\n'\n",
    ").format(cross_val_score(KNN_tuned_tfidf, X_test_tfidf, y_test_tfidf,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the time used by this model, it is unexpectedly low as it runs over a small dataset. This is the reason why the values obtained are so low when compared to the results obtained through the bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDG Classifier ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bag of Words***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDG classifier is fit on the training set. The SGD Classifier uses regularized linear models with stochastic gradient descendent learning. The model is updated in its learning rate after the gradient of the loss is estaimated for each sample. This classifier can work with sparse data se the one obtained from bag of words. In this case from the types of penalties the algorithm accepts, it uses L2 instead of a combination of L! and L2 implemented through Elastic Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters SGD BoW:\n",
      " {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "SGD_bow = SGDClassifier(class_weight = 'balanced', max_iter=1000)\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "loss_param = ['hinge', 'squared_hinge']\n",
    "penalty_param = ['l2', 'elasticnet']\n",
    "alpha_param = [0.1, 1, 10, 100]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'loss': loss_param,\n",
    "              'penalty': penalty_param,\n",
    "              'alpha': alpha_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "SGD_tuned_bow = GridSearchCV(SGD_bow, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "SGD_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters SGD BoW:\\n {}\\n').format(\n",
    "SGD_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters show that the smooting continues to be loose as a first option as it is a regression with a gradient descendent algorithm. Regarding the loss, the hinge loss is used which means that the real loss, in case it is not convergent due to the sparse data used is replaced by the upper bond forcing its convergence. Time required is significanlty higher than in the case of the Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "SGD_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = SGD_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model presents overfitting as all precision and recall are equal to one for every class. The confusion matrix shows a lower number of false negatives and positives per class being more or less evenly represented except for class three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.65      0.73      1091\n",
      "        1.0       0.89      0.53      0.67       509\n",
      "        2.0       0.98      0.44      0.61       684\n",
      "        3.0       0.71      0.97      0.82      2346\n",
      "\n",
      "avg / total       0.80      0.77      0.75      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[ 713    8    3  367]\n",
      " [  34  270    3  202]\n",
      " [  37    9  302  336]\n",
      " [  66   15    1 2264]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy BoW: 72.57 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print((\n",
    "    'SGD accuracy BoW: {0:.2f} %\\n'\n",
    ").format(cross_val_score(SGD_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the overall accuracy is 72.57%, very similar to the overall accuracy obtained using the multinomial classifier. The computational effort required by this model to achieve this accuracy is much higher than in the case of the multinomial classifier. Hence, from a production perspective, this model would not be recommended to move into production despite of its high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tf- idf ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD Classifier uses regularized linear models with stochastic gradient descendent learning. The model is updated in its learning rate after the gradient of the loss is estaimated for each sample. This classifier can work with sparse data se the one obtained from tfidf. In this case from the types of penalties the algorithm accepts, it uses L2 instead of a combination of L! and L2 implemented through Elastic Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters SDG Tfidf:\n",
      " {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'elasticnet'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "SGD_tfidf = SGDClassifier(class_weight = 'balanced', max_iter=1000)\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "loss_param = ['hinge', 'squared_hinge']\n",
    "penalty_param = ['elasticnet', 'l2' ]\n",
    "alpha_param = [1, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'loss': loss_param,\n",
    "              'penalty': penalty_param,\n",
    "              'alpha': alpha_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "SGD_tuned_tfidf = GridSearchCV(SGD_tfidf, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "SGD_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters SDG Tfidf:\\n {}\\n').format(\n",
    "SGD_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters show that the smooting continues to be loose as a first option as it is a regression with a gradient descendent algorithm. Regarding the loss, the hinge loss is used which means that the real loss, in case it is not convergent due to the sparse data used is replaced by the upper bond forcing its convergence. Time required is significanlty higher than in the case of the Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "SGD_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = SGD_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model presents overfitting as all precision and recall are equal to one for every class. The confusion matrix shows a lower number of false negatives and positives per class being more or less evenly represented except for class one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.95      1091\n",
      "        1.0       0.91      0.97      0.94       509\n",
      "        2.0       0.98      0.93      0.95       684\n",
      "        3.0       0.97      0.97      0.97      2346\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4630\n",
      "\n",
      "\n",
      "Confusion Matrix Tfidf: \n",
      "\n",
      " [[1081    1    0    9]\n",
      " [   6  497    0    6]\n",
      " [   7    2  656   19]\n",
      " [  12    6    4 2324]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy Tfidf: 80.78 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tfidf: \\n {}\\n').format(\n",
    "    classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix Tfidf: \\n\\n {}\\n\\n').format(confusion_tfidf))\n",
    "\n",
    "print((\n",
    "    'SGD accuracy Tfidf: {0:.2f} %\\n'\n",
    ").format(cross_val_score(SGD_tuned_tfidf, X_test_tfidf, y_test_tfidf,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the overall accuracy is 80.78%, very similar to the overall accuracy obtained using the multinomial classifier. The computational effort required by this model to achieve this accuracy is much higher than in the case of the multinomial classifier . Hence, from a production perspective, this model would not be recommended to move into production despite of its high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Bag of Words***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparamters of the random forest model have been tuned one by one. After trying to tune them all at once, a significant increase of the overall performance of the classifier was obtained with the proposed method (one by one). The parameters to be tuned are (in the same order as the hyperparameter tuning has been performed):\n",
    "\n",
    "N_estimators determining the number of trees that will be part of the algorithm.\n",
    "Max depth determining the size of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 31.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters Random Forest BoW:\n",
      " {'max_depth': 56, 'n_estimators': 350}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "rf_bow = RandomForestClassifier(class_weight = 'balanced')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "n_estimators_param = np.arange(250,401,20)\n",
    "max_depth_param = np.arange(46,63,2)\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'n_estimators': n_estimators_param,\n",
    "              'max_depth': max_depth_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "rf_tuned_bow = GridSearchCV(rf_bow, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "rf_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters Random Forest BoW:\\n {}\\n').format(rf_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned model is fit and run on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 14.8min finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "rf_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = rf_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model has significantly increase compared to the previous classifiers achieving 73%. This result is low for the type of classifier used. Additionally it is lower than the results obtained with other classifiers. In this case, author seven is the one that is decreasig the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.80      0.87      1091\n",
      "        1.0       0.99      0.74      0.85       509\n",
      "        2.0       1.00      0.73      0.84       684\n",
      "        3.0       0.82      0.99      0.90      2346\n",
      "\n",
      "avg / total       0.90      0.88      0.88      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[ 871    0    0  220]\n",
      " [  16  378    0  115]\n",
      " [  10    2  497  175]\n",
      " [  25    0    0 2321]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy BoW: 77.65 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print((\n",
    "    'Random Forest accuracy BoW: {0:.2f} %\\n'\n",
    ").format(cross_val_score(rf_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier requires more time to run than the Naive Bayes ones and throws poorer results than them. Author three is the one that is reducing the overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparamters of the random forest model have been tuned one by one. After trying to tune them all at once, a significant increase of the overall performance of the classifier was obtained with the proposed method (one by one). The parameters to be tuned are (in the same order as the hyperparameter tuning has been performed):\n",
    "\n",
    "N_estimators determining the number of trees that will be part of the algorithm.\n",
    "Max depth determining the size of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters Random Forest Tfidf:\n",
      " {'max_depth': 55, 'n_estimators': 180}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "rf_tfidf = RandomForestClassifier(class_weight = 'balanced')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "n_estimators_param = np.arange(100,201,10)\n",
    "max_depth_param = np.arange(50,71,5)\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {'n_estimators': n_estimators_param,\n",
    "              'max_depth': max_depth_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "rf_tuned_tfidf = GridSearchCV(rf_tfidf, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "rf_tuned_tfidf.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters Random Forest Tfidf:\\n {}\\n').format(\n",
    "rf_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned model is fit and run on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  6.7min finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "rf_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = rf_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model has significantly increase compared to the previous classifiers achieving 73%. This result is low for the type of classifier used. Additionally it is lower than the results obtained with other classifiers. In this case, author seven is the one that is decreasig the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.81      0.88      1091\n",
      "        1.0       1.00      0.76      0.86       509\n",
      "        2.0       1.00      0.74      0.85       684\n",
      "        3.0       0.83      0.99      0.90      2346\n",
      "\n",
      "avg / total       0.90      0.88      0.88      4630\n",
      "\n",
      "\n",
      "Confusion Matrix Tfidf: \n",
      "\n",
      " [[ 883    0    0  208]\n",
      " [  14  386    1  108]\n",
      " [   8    0  503  173]\n",
      " [  21    0    0 2325]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 275 out of 275 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy Tfidf: 76.93 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tfidf: \\n {}\\n').format(\n",
    "    classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix Tfidf: \\n\\n {}\\n\\n').format(confusion_tfidf))\n",
    "\n",
    "print((\n",
    "    'Random Forest accuracy Tfidf: {0:.2f} %\\n'\n",
    ").format(cross_val_score(rf_tuned_tfidf, X_test_tfidf, y_test_tfidf,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier requires more time to run than the Naive Bayes ones and throws poorer results than them. Author three is the one that is reducing the overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bag of Words ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear support vector classifier has been set up and tuned on the training data and run on the test set. The hyperparameters that have been tuned are:\n",
    "\n",
    "C parameter, acting on the margin hyperplane having a bigger margin when C is smaller. (The value of C will tell the SVM how much misclassification is to be avoided).\n",
    "The loss parameter.\n",
    "In this case the crammer singer algorithm is used to solve the multiclass classification problem. This algorithm optimizes the joint objective over all classes but it is not interesting from a production standpoint as it rarely leads to better accuracy and is more expensive to compute. Due to the size of the feature´s space the linear SVC has been used instead of the SVC due to computational restrictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters LinearSVC BoW:\n",
      " {'C': 1, 'loss': 'squared_hinge'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "LSVC_bow = LinearSVC(class_weight='balanced', multi_class = 'crammer_singer')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "\n",
    "loss_param = ['hinge','squared_hinge']\n",
    "C_param = [1, 10, 100, 100000]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = { 'loss': loss_param,\n",
    "             'C': C_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "LSVC_tuned_bow = GridSearchCV(LSVC_bow, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "LSVC_tuned_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters LinearSVC BoW:\\n {}\\n').format(\n",
    "LSVC_tuned_bow.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the parameters have been tunned the model is fit in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "LSVC_tuned_bow.fit(X_test_bow, y_test_bow)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_bow = LSVC_tuned_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although from a computational perspective it requires more effort, it presents better results than the previous algorithms. In this case, nearly 73% has been achieved competing agasint the multiclass algorithm in terms of accuracy but not in terms of computational effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report BoW: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98      1091\n",
      "        1.0       0.98      0.98      0.98       509\n",
      "        2.0       0.98      0.96      0.97       684\n",
      "        3.0       0.98      0.98      0.98      2346\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4630\n",
      "\n",
      "\n",
      "Confusion Matrix BoW: \n",
      "\n",
      " [[1076    2    3   10]\n",
      " [   5  497    0    7]\n",
      " [   6    2  654   22]\n",
      " [  18    8   10 2310]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC accuracy BoW: 72.27 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report BoW: \\n {}\\n').format(\n",
    "    classification_report(y_test_bow, predtest_y_bow,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_bow = confusion_matrix(y_test_bow, predtest_y_bow)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix BoW: \\n\\n {}\\n\\n').format(confusion_bow))\n",
    "\n",
    "print((\n",
    "    'Linear SVC accuracy BoW: {0:.2f} %\\n'\n",
    ").format(cross_val_score(LSVC_tuned_bow, X_test_bow, y_test_bow,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm presents overfitting as it can be seen from the classification report. Although recall and precision are one, in reality they are lower than one having an overall accuracy of 79.37%. Furthermore, the time required to fit the dataset is higher than the one required wuth the Naive Bayes algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear support vector classifier has been set up and tuned on the training data and run on the test set. The hyperparameters that have been tuned are:\n",
    "\n",
    "  C parameter, acting on the margin hyperplane having a bigger margin when C is smaller. (The value of C will tell the SVM how   much misclassification is to be avoided).\n",
    "   The loss parameter.\n",
    "In this case the crammer singer algorithm is used to solve the multiclass classification problem. This algorithm optimizes the joint objective over all classes but it is not interesting from a production standpoint as it rarely leads to better accuracy and is more expensive to compute. Due to the size of the feature´s space the linear SVC has been used instead of the SVC due to computational restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramenters Linear SVC Tfidf:\n",
      " {'C': 0.1, 'loss': 'squared_hinge'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "LSVC_tfidf = LinearSVC(class_weight='balanced', multi_class = 'crammer_singer')\n",
    "\n",
    "#Tune hyperparameters\n",
    "#Create range of values to fit parameters\n",
    "\n",
    "loss_param = ['hinge','squared_hinge']\n",
    "C_param = [0.1, 1, 10, 100]\n",
    "\n",
    "#Fit parameters\n",
    "parameters = {\n",
    "              'loss': loss_param,\n",
    "             'C': C_param}\n",
    "\n",
    "#Fit parameters using gridsearch\n",
    "LSVC_tuned_tfidf = GridSearchCV(LSVC_tfidf, param_grid=parameters,  n_jobs = -1, cv=kf, verbose = 1)\n",
    "\n",
    "#Fit the tunned classifier in the training space\n",
    "LSVC_tuned_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "#Print the best parameters\n",
    "print(('Best paramenters Linear SVC Tfidf:\\n {}\\n').format(LSVC_tuned_tfidf.best_params_))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the parameters have been tunned the model is fit in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "#Once the model has been trained test it on the test dataset\n",
    "LSVC_tuned_tfidf.fit(X_test_tfidf, y_test_tfidf)\n",
    "\n",
    "# Predict on test set\n",
    "predtest_y_tfidf = LSVC_tuned_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although from a computational perspective it requires more effort, it presents better results than the previous algorithms. In this case, nearly 79% has been achieved competing agasint the multiclass algorithm in terms of accuracy but not in terms of computational effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Tfidf: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.98      1091\n",
      "        1.0       0.95      0.98      0.97       509\n",
      "        2.0       0.97      0.96      0.97       684\n",
      "        3.0       0.99      0.97      0.98      2346\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4630\n",
      "\n",
      "\n",
      "Confusion Matrix Tfidf: \n",
      "\n",
      " [[1078    2    3    8]\n",
      " [   6  499    0    4]\n",
      " [   6    3  659   16]\n",
      " [  28   19   15 2284]]\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC accuracy Tfidf: 79.37 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model (testing)\n",
    "\n",
    "target_names = ['0.0', '1.0', '2.0', '3.0']\n",
    "\n",
    "print(('Classification Report Tfidf: \\n {}\\n').format(\n",
    "    classification_report(y_test_tfidf, predtest_y_tfidf,\n",
    "                          target_names=target_names)))\n",
    "\n",
    "confusion_tfidf = confusion_matrix(y_test_tfidf, predtest_y_tfidf)\n",
    "\n",
    "print((\n",
    "    'Confusion Matrix Tfidf: \\n\\n {}\\n\\n').format(confusion_tfidf))\n",
    "\n",
    "print((\n",
    "    'Linear SVC accuracy Tfidf: {0:.2f} %\\n'\n",
    ").format(cross_val_score(LSVC_tuned_tfidf, X_test_tfidf, y_test_tfidf,cv=kf).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The algorithm presents overfitting as it can be seen from the classification report. Although recall and precision are one, in reality they are lower than one having an overall accuracy of 79.37%. Furthermore, the time required to fit the dataset is higher than the one required wuth the Naive Bayes algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Improve accuracy of one of the models ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy improvement of all of the models has been done in the capstone project. To achieve this improvement the steps that have been taken have been:\n",
    "    \n",
    "1. Increase the dataset per author\n",
    "2. Increase the steps and the cleansing of the texts.\n",
    "3. Improve the feature generation and selection using tf-idf\n",
    "    \n",
    "The results obtained once all the stepst have been taken are:\n",
    "        \n",
    " 1. SGD Classifier: 87.12%\n",
    " 2. Multinomial Classifier: 87.02%\n",
    " 3. Linear Support Vector Machine: 86.48%\n",
    " 4. Logistic Regression: 84.88%\n",
    " 5. Bernouilli Classifier: 82.53%\n",
    " 6. Random Forest: 73.34%\n",
    " 7. KNN: 68.05%.\n",
    " \n",
    "From the initial set of results obtained in this challenge:\n",
    "\n",
    "1. Multinomial Classifier: 84.13% (BoW) & 83.46 (Tfidf)\n",
    "2. Bernoulli Classifier: 81.75% (BoW) & 81.58% (Tfidf)\n",
    "3. Random Forest: 77.64 (Bow) & 76.93% (Tfidf) \n",
    "3. Logistic Regression: 77.54 (Bow) & 80.43% (Tfidf) \n",
    "4. SGD Clasifier: 72.57% (BoW) & 80.78% (Tfidf)\n",
    "5. Support Vector Machine: 72.27% (BoW) & 79.37% (Tfidf)\n",
    "6. KNN: 59.72% (Bow) & 51,75 (Tfidf)\n",
    "\n",
    "From all the improvements made,  I pick up the one made in the SGD classifier that goes from 80.78% to 87.12%. The changes made in the model can be seen in the capstone project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
