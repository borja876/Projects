{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from nltk.corpus import gutenberg\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import math\n",
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Drill: tf-idf scores***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define tf_idf\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data\n",
    "phrase1 = tb(\"The best Monty Python sketch is the one about the dead parrot, I laughed so hard.\")\n",
    "phrase2 = tb(\"I laugh when I think about Python's Ministry of Silly Walks sketch, it is funny, funny, funny, the best!\")\n",
    "phrase3 = tb(\"Chocolate is the best ice cream dessert topping, with a great taste.\")\n",
    "phrase4 = tb(\"The Lumberjack Song is the funniest Monty Python bit: I can't think of it without laughing.\")\n",
    "phrase5 = tb(\"I would rather put strawberries on my ice cream for dessert, they have the best taste.\")\n",
    "phrase6 = tb(\"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in phrase 1\n",
      "\tWord: sketch, TF-IDF: 0.04332\n",
      "\tWord: Monty, TF-IDF: 0.04332\n",
      "\tWord: Python, TF-IDF: 0.02534\n",
      "\tWord: best, TF-IDF: 0.0114\n",
      "\tWord: taste, TF-IDF: 0.0\n",
      "\tWord: funny, TF-IDF: 0.0\n",
      "\tWord: laugh, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: dessert, TF-IDF: 0.0\n",
      "Top words in phrase 2\n",
      "\tWord: funny, TF-IDF: 0.16479\n",
      "\tWord: laugh, TF-IDF: 0.05493\n",
      "\tWord: sketch, TF-IDF: 0.03466\n",
      "\tWord: Python, TF-IDF: 0.02027\n",
      "\tWord: best, TF-IDF: 0.00912\n",
      "\tWord: taste, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: Monty, TF-IDF: 0.0\n",
      "\tWord: dessert, TF-IDF: 0.0\n",
      "Top words in phrase 3\n",
      "\tWord: dessert, TF-IDF: 0.05776\n",
      "\tWord: taste, TF-IDF: 0.03379\n",
      "\tWord: best, TF-IDF: 0.01519\n",
      "\tWord: funny, TF-IDF: 0.0\n",
      "\tWord: laugh, TF-IDF: 0.0\n",
      "\tWord: sketch, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: Monty, TF-IDF: 0.0\n",
      "\tWord: Python, TF-IDF: 0.0\n",
      "Top words in phrase 4\n",
      "\tWord: Monty, TF-IDF: 0.04077\n",
      "\tWord: Python, TF-IDF: 0.02385\n",
      "\tWord: best, TF-IDF: 0.0\n",
      "\tWord: taste, TF-IDF: 0.0\n",
      "\tWord: funny, TF-IDF: 0.0\n",
      "\tWord: laugh, TF-IDF: 0.0\n",
      "\tWord: sketch, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: dessert, TF-IDF: 0.0\n",
      "Top words in phrase 5\n",
      "\tWord: dessert, TF-IDF: 0.04332\n",
      "\tWord: taste, TF-IDF: 0.02534\n",
      "\tWord: best, TF-IDF: 0.0114\n",
      "\tWord: funny, TF-IDF: 0.0\n",
      "\tWord: laugh, TF-IDF: 0.0\n",
      "\tWord: sketch, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: Monty, TF-IDF: 0.0\n",
      "\tWord: Python, TF-IDF: 0.0\n",
      "Top words in phrase 6\n",
      "\tWord: taste, TF-IDF: 0.03119\n",
      "\tWord: best, TF-IDF: 0.0\n",
      "\tWord: funny, TF-IDF: 0.0\n",
      "\tWord: laugh, TF-IDF: 0.0\n",
      "\tWord: sketch, TF-IDF: 0.0\n",
      "\tWord: ice cream, TF-IDF: 0.0\n",
      "\tWord: Monty, TF-IDF: 0.0\n",
      "\tWord: Python, TF-IDF: 0.0\n",
      "\tWord: dessert, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Build list and vocabulary\n",
    "bloblist = [phrase1, phrase2, phrase3, phrase4, phrase5, phrase6]\n",
    "voc = ['Monty', 'Python', 'sketch', 'laugh', 'funny', 'best', 'ice cream', 'dessert', 'taste']\n",
    "\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in phrase {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in voc}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:9]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 1.8472978603872037,\n",
       " 'accompaniment': 2.2527629684953681,\n",
       " 'best': 1.336472236621213,\n",
       " 'bit': 2.2527629684953681,\n",
       " 'can': 2.2527629684953681,\n",
       " 'caramel': 2.2527629684953681,\n",
       " 'chocolate': 2.2527629684953681,\n",
       " 'cream': 1.5596157879354227,\n",
       " 'dead': 2.2527629684953681,\n",
       " 'dessert': 1.8472978603872037,\n",
       " 'fantastic': 2.2527629684953681,\n",
       " 'for': 2.2527629684953681,\n",
       " 'funniest': 2.2527629684953681,\n",
       " 'funny': 2.2527629684953681,\n",
       " 'great': 2.2527629684953681,\n",
       " 'hard': 2.2527629684953681,\n",
       " 'have': 2.2527629684953681,\n",
       " 'ice': 1.5596157879354227,\n",
       " 'is': 1.1541506798272583,\n",
       " 'it': 1.8472978603872037,\n",
       " 'laugh': 2.2527629684953681,\n",
       " 'laughed': 2.2527629684953681,\n",
       " 'laughing': 2.2527629684953681,\n",
       " 'lumberjack': 2.2527629684953681,\n",
       " 'ministry': 2.2527629684953681,\n",
       " 'mint': 2.2527629684953681,\n",
       " 'monty': 1.8472978603872037,\n",
       " 'my': 2.2527629684953681,\n",
       " 'of': 1.5596157879354227,\n",
       " 'on': 2.2527629684953681,\n",
       " 'one': 2.2527629684953681,\n",
       " 'parrot': 2.2527629684953681,\n",
       " 'put': 2.2527629684953681,\n",
       " 'python': 1.5596157879354227,\n",
       " 'rather': 2.2527629684953681,\n",
       " 'silly': 2.2527629684953681,\n",
       " 'sketch': 1.8472978603872037,\n",
       " 'so': 2.2527629684953681,\n",
       " 'song': 2.2527629684953681,\n",
       " 'strawberries': 2.2527629684953681,\n",
       " 'taste': 1.5596157879354227,\n",
       " 'tasty': 2.2527629684953681,\n",
       " 'the': 1.0,\n",
       " 'they': 2.2527629684953681,\n",
       " 'think': 1.8472978603872037,\n",
       " 'to': 2.2527629684953681,\n",
       " 'topping': 2.2527629684953681,\n",
       " 'walks': 2.2527629684953681,\n",
       " 'when': 2.2527629684953681,\n",
       " 'with': 2.2527629684953681,\n",
       " 'without': 2.2527629684953681,\n",
       " 'would': 2.2527629684953681}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"The best Monty Python sketch is the one about the dead parrot, I laughed so hard.\",\n",
    "          \"I laugh when I think about Python's Ministry of Silly Walks sketch, it is funny, funny, funny, the best!\",\n",
    "          \"Chocolate is the best ice cream dessert topping, with a great taste.\",\n",
    "          \"The Lumberjack Song is the funniest Monty Python bit: I can't think of it without laughing.\",\n",
    "          \"I would rather put strawberries on my ice cream for dessert, they have the best taste.\",\n",
    "          \"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Drills***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Emma by Jane Austen 1816 ]', 'VOLUME I', 'CHAPTER I', 'Emma Woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her .']\n"
     ]
    }
   ],
   "source": [
    "#reading in the data, this time in the form of paragraphs\n",
    "emma=gutenberg.paras('austen-emma.txt')\n",
    "\n",
    "#processing\n",
    "emma_paras=[]\n",
    "for paragraph in emma:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    para=[re.sub(r'VOLUME \\w+', '', word) for word in para]\n",
    "    para=[re.sub(r'CHAPTER \\w+', '', word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    emma_paras.append(' '.join(para))\n",
    "\n",
    "print(emma_paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 382\n",
      "Original sentence: A very few minutes more , however , completed the present trial .\n",
      "Tf_idf vector: {'minutes': 0.70710678118654746, 'present': 0.70710678118654746}\n"
     ]
    }
   ],
   "source": [
    "#Split data and vectorize\n",
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=10, # only use words that appear at X times (being X the number used)\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=False,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True, #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                           )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "emma_paras_tfidf=vectorizer.fit_transform(emma_paras)\n",
    "print(\"Number of features: %d\" % emma_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 75.8663260096\n",
      "Component 0:\n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.800488\n",
      "Emma could not have desired a more spirited rejection of Mr . Martin ' s prose .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.796912\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.781704\n",
      "Mrs . Weston was acting no part , feigning no feelings in all that she said to him in favour of the event . She had been extremely surprized , never more so , than when Emma first opened the affair to her ; but she saw in it only increase of happiness to all , and had no scruple in urging him to the utmost . She had such a regard for Mr . Knightley , as to think he deserved even her dearest Emma ; and it was in every respect so proper , suitable , and unexceptionable a connexion , and in one respect , one point of the highest importance , so peculiarly eligible , so singularly fortunate , that now it seemed as if Emma could not safely have attached herself to any other creature , and that she had herself been the stupidest of beings in not having thought of it , and wished it long ago . How very few of those men in a rank of life to address Emma would have renounced their own home for Hartfield !    0.767525\n",
      "\" Emma ,\" said Mr . Knightley presently , \" I have a piece of news for you .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.766765\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.762165\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.761571\n",
      "Emma was most agreeably surprized . Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.753738\n",
      "The intermediate month was the one fixed on , as far as they dared , by Emma and Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.743976\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.724880\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "\" Oh !     0.997991\n",
      "\" Oh !\"    0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !\"    0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !     0.997991\n",
      "\" Oh !     0.997991\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .                                                                                                                                                                                                                                                                          0.750133\n",
      "\" Why will not you write one yourself for us , Mr .                                                                                                                                                                                                                                                                                                                                  0.682854\n",
      "\"` Mr .                                                                                                                                                                                                                                                                                                                                                                              0.682854\n",
      "The carriage came : and Mr . Woodhouse , always the first object on such occasions , was carefully attended to his own by Mr . Knightley and Mr . Weston ; but not all that either could say could prevent some renewal of alarm at the sight of the snow which had actually fallen , and the discovery of a much darker night than he had been prepared for .                       0.676512\n",
      "Mr . Knightley had done all in his power for Mr . Woodhouse ' s entertainment .                                                                                                                                                                                                                                                                                                      0.671532\n",
      "Mr . Woodhouse at last was off ; but Mr . Knightley , instead of being immediately off likewise , sat down again , seemingly inclined for more chat .                                                                                                                                                                                                                                0.652959\n",
      "\" Mr . Knightley was there too , was he ?\"                                                                                                                                                                                                                                                                                                                                           0.634365\n",
      "Mr . Knightley grew angry .                                                                                                                                                                                                                                                                                                                                                          0.634365\n",
      "She had not time to know how Mr . Elton took the reproof , so rapidly did another subject succeed ; for Mr . John Knightley now came into the room from examining the weather , and opened on them all with the information of the ground being covered with snow , and of its still snowing fast , with a strong drifting wind ; concluding with these words to Mr . Woodhouse :    0.633847\n",
      "\" I do own myself to have been completely mistaken in Mr . Elton .                                                                                                                                                                                                                                                                                                                   0.622071\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "\" So do I ,\" said Mrs . Weston gently , \" very much .\"                                                                                                                                                                                                           0.723249\n",
      "\" No trouble in the world , ma ' am ,\" said the obliging Mrs . Ford .                                                                                                                                                                                            0.657123\n",
      "\" Well ,\" said Mrs . Weston , smiling , \" you give him credit for more simple , disinterested benevolence in this instance than I do ; for while Miss Bates was speaking , a suspicion darted into my head , and I have never been able to get it out again .    0.632900\n",
      "\" My advice ,\" said Mrs . Weston kindly and persuasively , \" I certainly do feel tempted to give .                                                                                                                                                               0.621415\n",
      "\" Now , ma ' am ,\" said Jane to her aunt , \" shall we join Mrs .                                                                                                                                                                                                 0.587568\n",
      "Miss Bates and Miss Fairfax , escorted by the two gentlemen , walked into the room ; and Mrs . Elton seemed to think it as much her duty as Mrs . Weston ' s to receive them .                                                                                   0.579231\n",
      "\" Well done , Mrs .                                                                                                                                                                                                                                              0.573555\n",
      "[ To Mrs .                                                                                                                                                                                                                                                       0.573555\n",
      "\" How do you do , Mrs . Ford ?                                                                                                                                                                                                                                   0.573555\n",
      "\" Mrs . Dixon !                                                                                                                                                                                                                                                  0.573555\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "CHAPTER II      1.0\n",
      "CHAPTER IV      1.0\n",
      "CHAPTER II      1.0\n",
      "CHAPTER III     1.0\n",
      "CHAPTER XVI     1.0\n",
      "CHAPTER XIV     1.0\n",
      "CHAPTER X       1.0\n",
      "CHAPTER V       1.0\n",
      "CHAPTER X       1.0\n",
      "CHAPTER XVII    1.0\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c266f0be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Drill 0: Test set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: \" And I am quite serious too , I assure you ,\" replied Mrs . Elton gaily , \" in resolving to be always on the watch , and employing my friends to watch also , that nothing really unexceptionable may pass us .\"\n",
      "Tf_idf vector: {'really': 0.35355339059327373, 'pass': 0.35355339059327373, 'assure': 0.35355339059327373, 'mrs': 0.35355339059327373, 'friends': 0.35355339059327373, 'quite': 0.35355339059327373, 'elton': 0.35355339059327373, 'replied': 0.35355339059327373}\n"
     ]
    }
   ],
   "source": [
    "#Reshapes the vectorizer output into something people can read\n",
    "X_test_tfidf_csr = X_test_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_test_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_test_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_test_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_test[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 79.6598094568\n",
      "Component 0:\n",
      "The event was more favourable to Mr . Woodhouse than to Emma .                                                                                                                                                                            0.717394\n",
      "\" Well , Mrs . Weston ,\" said Emma triumphantly when he left them , \" what do you say now to Mr . Knightley ' s marrying Jane Fairfax ?\"                                                                                                  0.698278\n",
      "In this walk Emma and Mr . Weston found all the others assembled ; and towards this view she immediately perceived Mr . Knightley and Harriet distinct from the rest , quietly leading the way .                                          0.697127\n",
      "\" He is a person I never think of from one month ' s end to another ,\" said Mr . Knightley , with a degree of vexation , which made Emma immediately talk of something else , though she could not comprehend why he should be angry .    0.684809\n",
      "Emma and Harriet had been walking together one morning , and , in Emma ' s opinion , had been talking enough of Mr . Elton for that day .                                                                                                 0.676590\n",
      "Mr . Elton had retreated into the card - room , looking ( Emma trusted ) very foolish .                                                                                                                                                   0.672216\n",
      "Emma was extremely gratified . They were interrupted by the bustle of Mr . Weston calling on every body to begin dancing again .                                                                                                          0.670927\n",
      "\" And when ,\" thought Emma , \" will there be a beginning of Mr .                                                                                                                                                                          0.657018\n",
      "Emma would not have smiled for the world , and only said , \" Is Mr . Elton gone on foot to Donwell ? He will have a hot walk .\"                                                                                                           0.648608\n",
      "Emma was more than half in hopes of Mr . Elton ' s having dropt a hint .                                                                                                                                                                  0.642841\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "\" Oh !            0.999456\n",
      "\" Oh no , no !    0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Oh !            0.999456\n",
      "\" Me ! oh !       0.999456\n",
      "\" Oh !            0.999456\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "\" She must have some motive , more powerful than appears , for refusing this invitation ,\" was Emma ' s conclusion .                                0.701628\n",
      "Emma had done .                                                                                                                                     0.701628\n",
      "Emma wondered on what , of all the medley , she would fix .                                                                                         0.701628\n",
      "\" And I do envy him , Emma .                                                                                                                        0.701628\n",
      "\" My Emma !\"                                                                                                                                        0.701628\n",
      "\" Such an imagination has crossed me , I own , Emma ; and if it never occurred to you before , you may as well take it into consideration now .\"    0.701628\n",
      "\" Emma !\"                                                                                                                                           0.701628\n",
      "Emma denied none of it aloud , and agreed to none of it in private .                                                                                0.701628\n",
      "Emma was in no danger of forgetting .                                                                                                               0.683578\n",
      "Emma seriously hoped she would .                                                                                                                    0.671660\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "\" I am not fond of dinner - visiting ,\" said he \" I never was .                                                                                                                                       0.676805\n",
      "\" It is to be a secret , I conclude ,\" said he .                                                                                                                                                      0.675223\n",
      "\" Colonel and Mrs . Campbell are to be in town again by midsummer ,\" said Jane .                                                                                                                      0.642224\n",
      "\" Well  if you please ,\" said Mrs . Weston rather hesitating , \" if you think she will be of any use .\"                                                                                               0.637882\n",
      "\" It is Frank and Miss Fairfax ,\" said Mrs . Weston .                                                                                                                                                 0.627133\n",
      "\" Do come with me ,\" said Mrs . Weston , \" if it be not very disagreeable to you .                                                                                                                    0.620625\n",
      "\" Well ,\" said Mrs . Weston , laughing , \" perhaps the greatest good he could do them , would be to give Jane such a respectable home .\"                                                              0.611626\n",
      "\" I should not wonder ,\" said Mrs . Weston , \" if Miss Fairfax were to have been drawn on beyond her own inclination , by her aunt ' s eagerness in accepting Mrs . Elton ' s civilities for her .    0.597601\n",
      "\" If you are very kind ,\" said he , \" it will be one of the waltzes we danced last night ; let me live them over again .                                                                              0.569466\n",
      "\" Well ,\" said Mrs . Elton , laughing , \" we shall see .\"                                                                                                                                             0.556614\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "CHAPTER XV       1.0\n",
      "CHAPTER XII      1.0\n",
      "CHAPTER XIV      1.0\n",
      "CHAPTER XIX      1.0\n",
      "CHAPTER XIII     1.0\n",
      "CHAPTER XV       1.0\n",
      "CHAPTER XIII     1.0\n",
      "CHAPTER IV       1.0\n",
      "CHAPTER VII      1.0\n",
      "CHAPTER XVIII    1.0\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_test_lsa = lsa.fit_transform(X_test_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_test_lsa,index=X_test)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c266d39fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 Mr . Woodhouse had so completely made up his mind to the visit , that in spite of the increasing coldness , he seemed to have no idea of shrinking from it , and set forward at last most punctually with his eldest daughter in his own carriage , with less apparent consciousness of the weather than either of the others ; too full of the wonder of his own going , and the pleasure it was to afford at Randalls to see that it was cold , and too well wrapt up to feel it .\n",
      "1 \" Oh !\n",
      "2 \" Oh no , no !\n",
      "3 Such was Jane Fairfax ' s history .\n",
      "4 \" That has been a good deal the case , my dear ; but not to the degree you mention .\n",
      "5 \" And I am quite serious too , I assure you ,\" replied Mrs . Elton gaily , \" in resolving to be always on the watch , and employing my friends to watch also , that nothing really unexceptionable may pass us .\"\n",
      "6 \" And here is Mrs . Weston and Mr . Frank Churchill too ! Quite delightful ; so many friends !\"\n",
      "7 \" You may well class the delight , the honour , and the comfort of such a situation together ,\" said Jane , \" they are pretty sure to be equal ; however , I am very serious in not wishing any thing to be attempted at present for me .\n",
      "8 Harriet , Mr . Elton , and Mr . Knightley , their own especial set , were the only persons invited to meet them ; the hours were to be early , as well as the numbers few ; Mr . Woodhouse ' s habits and inclination being consulted in every thing .\n",
      "9 \" Oh !\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_test_lsa) * np.asmatrix(X_test_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_test).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap shows that sentences 1,2 present similarity between them and with sentence 9 as oh! appears in all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Drill 1: Tweaking tf-idf***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the threshold regarding the number of times that a word appears (min_df) increases (from 2 to 10), the noise is reduced reducing the number of features significantly (form >2000 to <1000) and the percentage of variance explained increases to 68%.\n",
    "\n",
    "Dropping the words that appear in certain number of paragraphs (max_df) from (0.5 to 0.2) has a lower impact than the number of times a word appears in the text. It could be due to the fact that after cleaning the text from punctuation and stopwords there are not too many words that appear in more than one of the paragraphs. Increasing this threshold makes the number of features higher as it will be harder to find words that are repeated in a higher number of paragraphs.\n",
    "\n",
    "The use of n-grams in a range 1-3 penalises the number of features used to have the same percentage of variance explained. More features are required to achieve the same level of variance.\n",
    "\n",
    "Not using inverse frequency in the vectorizer increases the variance explained up to 75% with the same number of features than when it is used. In  this case, max_df has a significant impact in the level of variance explained (73% for 0.1 to 76% with 0.9) with the same number of features (roughly 382-5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
